# 基本形式

* 给定由d个属性描述的 $ X = [X_1，X_2, X_3 \cdots X_n ] ​$ 也可表示为 $ X^{(i)} = [X_1^{(i)}, X_2^{(i)}, X_3^{(i)} \cdot X_n^{(i)}] ​$ 代表第i行（第i个样本）的第1,2,3 .. n个特征

* 一般的向量形式可以写为 $$ f(X) = \omega^{T}X + b $$ 其中 $ \omega = (\omega_1, \omega_2 \cdots \omega_n) $. $ \omega $ 和b学得之后，模型就可以确认

* 许多更强大的非线性模型(nonlinear model)可以再线性模型的基础上引入 **层级结构** 和 **高维映射** 得到

* **可解释性** “ $f_{好瓜} = 0.2 * X_{色泽} + 0.5 * X_{根蒂} + 0.3 * X_{敲声} + 1 $ " ，则意味着根蒂判断瓜好不好最要紧，而敲声比色泽更重要

# 线性回归

**目标** ： 使 $ \sum\limits_{i=1}^{m} (y^{(i)} - \hat y^{(i)})^2 $ 尽可能小 。      

​		$$ \hat y^{(i)} = \omega_0 + \omega_1X_1^{(i)} + \omega_2X_2^{(i)} + \omega_nX_n^{(i)} $$ 



找到 $ \omega_0, \omega_1, \omega_2 \cdots \omega_n $ 使 

​		$$ \sum\limits_{i=1}^{m} (y^{(i)} - \hat y^{(i)})^2 $$ 

最小



令 $ \omega = ( \omega_0,\omega_1,\omega_2 \cdots \omega_n )^T $  ；$ X^{(i)} = (X_0^{(i)},X_1^{(i)},X_2^{(i)},\cdots,X_n^{(i)}) $

> 其中 $ \omega_0 代表截距，其他\omega 代表斜率 , X_0^{(i)} 需要自己创造一个，以方便凑成向量点乘， 其中X_0^{(i)} == 1 $



得到 $ \hat y = X \cdot \theta $ ； 其中 $ \sum\limits_{i=1}^{m} (y^{(i)} - \hat y^{(i)})^2 $ 平方和的形式可以转换为矩阵点乘的形式

​		$$ (y - X \cdot \theta)^T(y - X \cdot \theta) $$

# 最终求解公式



> 推导得到最简公式

​		$ \theta = (X_b^{T} \cdot X_b)^{-1} \cdot X_b^T \cdot y $
我们的目标就是求解得到这个 $\theta$

# 优劣

问题： 时间复杂度高 : $ O(n^3) (优化O(n^2.4)) $


优点 ： 不需要对数据做归一化处理
